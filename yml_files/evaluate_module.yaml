
name: Evaluate module

description: Evaluate the predicted results

inputs:

  - {name: input_data,              type: String,                                         description: 'Predicted data path.'}

  - {name: pr,                      type: Boolean,          default: 'True',              description: 'Whether to calculate precision-recall(pr).'}

  - {name: roc,                     type: Boolean,          default: 'True',              description: 'Whether to calculate receiver operating characteristic(ROC).'}

  - {name: label_columns,           type: String,                                         description: '[Optional]label columns,the order should responding to probability_columns. Separated by " " , such as "col1 col2", default="[L|l]abel*".'}

  - {name: probability_columns,     type: String,                                         description: '[Optional]probability columns, the order should responding to label columns. Separated by " " , such as "col1 col2", if None, default="[P|p]robability*".'}

  - {name: output_dir,              type: String,                                         description: 'Directory to save evaluated results.'}


outputs:

  - {name: output_dir,              type: String,             description: 'Directory to save evaluated results.'}

implementation:

  container:


    command: [python3, func_modules/evaluate_module.py]

    args: [

      --input_data,            {inputValue: input_data},

      --pr,                    {inputValue: pr},

      --roc,                   {inputValue: roc},

      --label_columns,         {inputValue: label_columns},

      --probability_columns,   {inputValue: probability_columns},

      --output_dir,            {inputValue: output_dir},


      --output_dir_uri,        {outputPath: output_dir},


    ]

